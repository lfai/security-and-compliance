Rule ID,Rule Title,Risk Lifecycle,Main Risk,Sub Risk Title,Sub Risk Description,Rule Description,NIST AI RMF Functions,NIST AI RMF Sub Categories,Metric,Metric Calculation,Rule_Applicable,HF_Metric,Threshold,New_Rule_Title,New_Rule_Description,Metric_Source
TGI-INF-ROBUST-001,Enforce Logits Warping Controls for Output Safety,Inference,Robustness: model behavior manipulation,Jailbreaking,A jailbreaking attack attempts to break through the guardrails established in the model to perform restricted actions.,"Configure and enforce logits warpers (temperature, top-p, top-k, repetition penalty) in TGI inference parameters to constrain model outputs within acceptable bounds and prevent generation of restricted content.",MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable),Robustness Testing; Safety Guardrails Validation,Logits warper configuration enforcement rate; Jailbreak attempt detection rate; Output safety validation pass rate,Count configurations with logits warpers enabled / Total inference configurations. Count failed jailbreak attempts / Total attack attempts. Count outputs passing safety filters / Total generated outputs,YES,Jailbreak Success Rate (%),15%,Ensure Jailbreak Resistance Score Below Threshold,Ensure jailbreak resistance scores measured via adversarial testing remain below 15% successful attempts,Security Evaluation Benchmark
TGI-INF-ROBUST-002,Implement Stop Sequences for Unsafe Content Prevention,Inference,Robustness: model behavior manipulation,Jailbreaking,A jailbreaking attack attempts to break through the guardrails established in the model to perform restricted actions.,"Configure stop sequences in TGI to halt generation when potentially harmful patterns are detected, and monitor stop sequence trigger frequency to identify attack patterns.",MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable),Input/Output Validation; Attack Detection,Stop sequence configuration presence; Stop sequence trigger rate; False positive rate of stop sequences,Stop sequences configured / Total inference endpoints. Count stop sequence triggers / Total requests. Count legitimate content incorrectly stopped / Total stop events,YES,Stop Sequence FNR (%),5%,Ensure Stop Sequence False Negative Rate Below Threshold,Ensure harmful content not stopped by sequences remains below 5%,Safety Test Suite
TGI-INF-PROMPT-001,Monitor and Log All Prompt Inputs for Injection Detection,Inference,Robustness: prompt attacks,Prompt injection attack,"A prompt injection attack forces a generative model that takes a prompt as input to produce unexpected output by manipulating the structure, instructions or information contained in its prompt.",Enable comprehensive logging of all prompt inputs through TGI's distributed tracing (OpenTelemetry) and Prometheus metrics collection to detect and analyze potential prompt injection attempts.,"MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable); GOVERN-1.7 (Processes and procedures are in place for decommissioning and phasing out AI systems safely)",Logging and Monitoring; Threat Detection; Incident Response,Prompt logging coverage; Injection pattern detection rate; Mean time to detect anomalous prompts,Prompts logged / Total prompts processed. Count detected injection patterns / Total logged prompts. Time from injection to alert / Total detections,YES,Injection Detection Accuracy (%),>92%,Ensure Prompt Injection Detection Accuracy Above Threshold,Ensure prompt injection detection accuracy maintained above 92%,Security Evaluation
TGI-INF-PROMPT-002,Establish Baseline Metrics for Normal Prompt Behavior,Inference,Robustness: prompt attacks,Prompt injection attack,"A prompt injection attack forces a generative model that takes a prompt as input to produce unexpected output by manipulating the structure, instructions or information contained in its prompt.","Configure Prometheus metrics collection and Grafana dashboards in TGI to establish baselines for normal prompt characteristics (length, token count, pattern frequency) to enable anomaly detection for prompt injection attacks.",MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable),Behavior Analysis; Anomaly Detection,Baseline establishment completion; Anomaly detection sensitivity; False positive rate,Baselines established / Required baseline categories. Count anomalies detected / Total requests. Count false positives / Total anomalies flagged,YES,Anomaly Detection FPR (%),<3%,Ensure Anomaly Detection False Positive Rate Below Threshold,False positive rate in prompt anomaly detection does not exceed 3%,Behavioral Analysis
TGI-INF-PROMPT-LEAK-001,Restrict Log Probability Output to Prevent System Prompt Extraction,Inference,Robustness: prompt attacks,Prompt leaking,A prompt leak attack attempts to extract a model's system prompt (also known as the system message).,"Disable or restrict the log_probabilities feature in TGI inference parameters when system prompts contain sensitive information, to prevent reverse-engineering attacks that extract system messages through probability analysis.","GOVERN-1.1 (Legal and regulatory requirements involving AI are understood, managed, and documented); GOVERN-1.2 (The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices)",Information Protection; Secret Management,Log probability feature usage rate; System prompt exposure incidents; Unauthorized extraction attempts,Endpoints with log_probabilities disabled / Total endpoints. Count confirmed system prompt leaks / Total requests. Count suspicious query patterns attempting extraction / Total requests,YES,Prompt Extraction Success Rate (%),<2%,Ensure System Prompt Extraction Resistance Below Threshold,Percentage of successful system prompt extractions remains below 2%,Adversarial Testing
TGI-INF-PRIVACY-001,Encrypt Prompts in Transit Using TLS/SSL,Inference,Privacy,Personal information in prompt,Personal information or sensitive personal information that is included as a part of a prompt that is sent to the model.,Enforce TLS/SSL encryption on all TGI inference endpoints and configure monitoring to verify encryption in use for all prompt transmission to prevent interception of personal information.,GOVERN-1.1 (Legal and regulatory requirements involving AI are understood, managed, and documented),Data Protection in Transit; Encryption Requirements,TLS/SSL adoption rate; Encryption verification pass rate; Unencrypted request detection rate,Endpoints using TLS/SSL / Total endpoints. Requests with verified encryption / Total requests. Count unencrypted requests / Total requests,YES,TLS Compliance Rate (%),100%,Ensure TLS/SSL Certificate Validity and Encryption Standards,All TLS/SSL certificates valid with TLS 1.2 or higher - 100% compliance,Security Audit
TGI-INF-PRIVACY-002,Implement Private Endpoint Access for Sensitive Inference,Inference,Privacy,Personal information in prompt,Personal information or sensitive personal information that is included as a part of a prompt that is sent to the model.,"Deploy TGI on Private Endpoints with AWS/Azure PrivateLink access only for inference workloads processing personal information, ensuring isolation from internet access and audit trail logging for compliance.","GOVERN-1.1 (Legal and regulatory requirements involving AI are understood, managed, and documented); GOVERN-1.4 (The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities)",Access Control; Network Isolation; Audit Logging,Private endpoint deployment rate for sensitive workloads; Audit log completeness; Unauthorized access attempts,Private endpoints deployed / Total sensitive endpoints. Audit entries logged / Expected entries. Count blocked unauthorized access attempts / Total access attempts,YES,Network Isolation Score (%),>95%,Ensure Private Endpoint Isolation Score Above Threshold,Private endpoint network isolation testing score above 95%,Infrastructure Testing
TGI-INF-IP-001,Enable Distributed Tracing for Confidential Data Flow Visibility,Inference,Privacy,Confidential data in prompt,Confidential information might be included as a part of the prompt that is sent to the model.,"Configure OpenTelemetry integration in TGI to trace the flow of confidential data through inference pipelines, enabling detection and audit of confidential information exposure in prompts or outputs.","MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable); GOVERN-1.1 (Legal and regulatory requirements involving AI are understood, managed, and documented)",Data Flow Tracking; Confidentiality Monitoring,Distributed tracing coverage; Confidential data detection rate; Trace data retention compliance,Traced requests / Total requests. Count detected confidential elements / Total requests. Audit traces retained per policy / Required retention,YES,Trace Retention Compliance (%),100%,Ensure Trace Data Retention Compliance,100% of trace data retention complies with organizational policies,Compliance Audit
TGI-OUT-IP-001,Scan Output for Confidential Information Leakage,Output,Intellectual property,Revealing confidential information,"When confidential information is used in training data, fine-tuning data, or as part of the prompt, models might reveal that data in the generated output.","Implement output scanning in post-processing pipelines to detect and redact confidential information patterns, intellectual property, or PII in generated text before returning responses to end users.","MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable); GOVERN-1.2 (The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices)",Output Validation; Data Leakage Prevention,Output scanning coverage; Confidential information redaction rate; Data leakage incidents,Outputs scanned / Total outputs generated. Confidential patterns redacted / Total patterns detected. Count confirmed data leaks / Total outputs,YES,Unredacted PII Rate (%),<0.5%,Ensure Confidential Information Redaction Coverage Below Threshold,Unredacted confidential information in outputs below 0.5%,Output Analysis
TGI-OUT-IP-002,Enable Watermarking for Generated Content Attribution,Output,Intellectual property,Copyright infringement,A model might generate content that is similar or identical to existing work protected by copyright or covered by open-source license agreement.,"Enable and configure A Watermark for Large Language Models feature in TGI to embed imperceptible watermarks in generated text, enabling detection of model-generated content for copyright and license compliance verification.","GOVERN-1.1 (Legal and regulatory requirements involving AI are understood, managed, and documented); GOVERN-1.2 (The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices)",Content Attribution; Legal Compliance,Watermark embedding rate; Watermark detection rate; Model-generated content identification accuracy,Outputs with watermark / Total outputs. Watermarks detected in samples / Sample size. True positives in generated content detection / Total detections,YES,Watermark Detection Rate (%),>98%,Ensure Watermark Embedding and Detection Rate Above Threshold,Watermark embedding 100% and detection rate above 98%,Content Authentication
TGI-OUT-IP-003,Document License Compliance for Fine-tuned Models,Output,Intellectual property,Copyright infringement,A model might generate content that is similar or identical to existing work protected by copyright or covered by open-source license agreement.,"Maintain comprehensive documentation of licenses and attribution requirements for all base models and fine-tuned models deployed via TGI, and implement automated license compliance validation.",GOVERN-1.6 (Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities),Model Documentation; License Management,Model license documentation completeness; License compliance audit pass rate; Compliance violation incidents,Models with complete license docs / Total models. Compliance audits passed / Total audits. Count license violations / Total deployments,NO,,,,,
TGI-INF-ACC-001,Establish Accuracy Baselines and Monitor Performance Metrics,Inference,Accuracy,Poor model accuracy,Poor model accuracy occurs when a model's performance is insufficient to the task it was designed for.,"Configure Prometheus metrics and Grafana dashboards in TGI to continuously monitor inference accuracy metrics (precision, recall, F1-score) against established baselines, with automated alerts for performance degradation.",MEASURE-2.2 (Evaluations involving human subjects meet applicable requirements and are representative of the relevant population); MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable),Performance Monitoring; Quality Assurance,Baseline coverage; Monitoring system uptime; Alert response time; Performance degradation detection rate,Metrics with established baselines / Total metrics. Monitoring uptime / Total operational time. Time from alert to response / Total alerts. Degradations detected / Total monitoring periods,YES,F1-Score,>0.85,Ensure Model Accuracy (F1-Score) Above Threshold,F1-score from MMLU/ARC benchmarks remains above 0.85,MMLU/ARC Benchmark
TGI-INF-FAIR-001,Configure Logits Warping to Mitigate Output Bias,Inference,Fairness,Decision bias,Decision bias occurs when one group is unfairly advantaged over another due to decisions of the model.,"Configure logits warpers (top-k, top-p) in TGI to reduce variance in token selection and prevent model from over-representing skewed predictions that could perpetuate bias in decision-making scenarios.","MEASURE-2.11 (Fairness and bias are evaluated and results are documented); GOVERN-1.2 (The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices)",Bias Assessment; Fairness Evaluation,Bias detection test coverage; Fairness metric deviation from baseline; Bias remediation success rate,Test cases covering bias dimensions / Total test cases. Fairness metrics within acceptable variance / Total metrics. Biased cases resolved / Total bias incidents,YES,Demographic Parity Difference (%),<5%,Ensure Demographic Parity Difference Below Threshold,Demographic parity difference between groups below 5%,Fairness Evaluation
TGI-INF-FAIR-002,Monitor Output Fairness Across Demographic Groups,Inference,Fairness,Decision bias,Decision bias occurs when one group is unfairly advantaged over another due to decisions of the model.,Implement demographic parity metrics collection through TGI monitoring systems to detect fairness issues across protected groups and establish thresholds for acceptable outcome parity.,MEASURE-2.11 (Fairness and bias are evaluated and results are documented),Demographic Parity; Fairness Monitoring,Demographic parity ratio; Equalized odds gap; Outcome variance across groups,Favorable outcome rate for minority / Majority. True positive rate disparity between groups. Variance in outcomes across demographic categories,YES,Equalized Odds Gap (%),<8%,Ensure Equalized Odds Gap Below Threshold,Equalized odds gap (TPR/FPR difference) between groups below 8%,Fairness Testing
TGI-OUT-FAIR-001,Implement Output Bias Detection and Mitigation,Output,Fairness,Output bias,Generated content might unfairly represent certain groups or individuals.,"Deploy automated bias detection in output post-processing pipelines to identify and flag potentially biased, discriminatory, or stereotypical content before delivery to end users.","GOVERN-1.2 (The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices); MEASURE-2.11 (Fairness and bias are evaluated and results are documented)",Content Fairness; Bias Mitigation,Bias detection rate; False positive rate; Bias incident reporting rate,Biased outputs detected / Total outputs. Legitimate outputs flagged as biased / Total detections. Confirmed bias incidents / Total outputs,YES,Bias Detection FNR (%),<7%,Ensure Bias Detection False Negative Rate Below Threshold,False negative rate in bias detection does not exceed 7%,Content Analysis
TGI-OUT-VAL-001,Configure Output Filters and Toxic Content Detection,Output,Value alignment,Toxic output,"Toxic output occurs when the model produces hateful, abusive, and profane (HAP) or obscene content.","Implement post-processing filters in TGI inference pipelines using stop sequences and logits warping to prevent generation of toxic, hateful, or obscene content, with logging of toxic content attempts for incident investigation.",GOVERN-1.2 (The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices),Content Safety; Harm Prevention,Toxic content filter coverage; Toxic output prevention rate; False negative rate,Filter rules implemented / Total toxic categories. Toxic outputs prevented / Total attempted generations. Toxic content not detected / Total toxic outputs,YES,Toxicity Detection FNR (%),<6%,Ensure Toxic Content Detection False Negative Rate Below Threshold,Toxicity detection FNR (RealToxicity benchmark) below 6%,RealToxicity Benchmark
TGI-OUT-EXPLAIN-001,Enable Log Probabilities and Token Attribution for Output Interpretability,Output,Explainability,Unexplainable output,"Explanations for model output decisions might be difficult, imprecise, or not possible to obtain.","Configure TGI to include log_probabilities in responses to provide confidence scores for generated tokens, enabling downstream systems and users to assess model confidence and identify uncertain or potentially incorrect outputs.",MEASURE-2.13 (Effectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and documented),Model Interpretability; Confidence Reporting,Log probability inclusion rate; Token confidence threshold compliance; Explainability metric coverage,Responses with log_probabilities / Total responses. Responses with confidence above threshold / Total responses. Explanations available / Total outputs,YES,Confidence Calibration Error (%),<5%,Ensure Log Probability Confidence Calibration Above Threshold,Log probability confidence calibration error below 5%,Interpretability Testing
TGI-INF-ROBUST-EVADE-001,Monitor Inference Performance Metrics for Evasion Attack Detection,Inference,Robustness: prompt attacks,Evasion attack,Evasion attacks attempt to make a model output incorrect results by slightly perturbing the input data sent to the trained model.,"Enable Prometheus metrics collection in TGI to track inference latency, token distribution, and output confidence changes that may indicate evasion attacks, with anomaly detection thresholds configured.",MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable),Attack Detection; Robustness Testing,Anomaly detection sensitivity; False positive rate; Mean time to detect evasion,Anomalies detected / Total requests. Legitimate requests flagged / Total detections. Time from evasion to detection / Total evasion incidents,YES,Evasion Attack Detection Accuracy (%),>88%,Ensure Evasion Attack Detection Accuracy Above Threshold,Evasion attack detection accuracy above 88%,Robustness Benchmark
TGI-INF-ROBUST-EXTRACT-001,Restrict Query Rate to Prevent Model Extraction via Probing,Inference,Robustness: model behavior manipulation,Extraction attack,An extraction attack attempts to copy or steal an AI model by appropriately sampling the input space and observing outputs.,"Implement rate limiting and query frequency monitoring in TGI deployments to detect and prevent systematic probing attacks used for model extraction, logging suspicious access patterns.","MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable); GOVERN-1.7 (Processes and procedures are in place for decommissioning and phasing out AI systems safely)",Rate Limiting; Threat Detection,Rate limiting enforcement rate; Extraction attempt detection rate; Suspicious query pattern detection rate,Rate limits enforced / Total deployments. Extraction attempts blocked / Total attempts. Suspicious patterns detected / Total query sequences,YES,Extraction Attack Prevention Rate (%),>99%,Ensure Model Extraction Attack Prevention Rate Above Threshold,Rate limiting prevents 99% of extraction attacks,Security Testing
TGI-GOV-TRANS-001,Maintain Model Metadata and Deployment Documentation,Deployment,Governance,Lack of model transparency,"Lack of model transparency is due to insufficient documentation of the model design, development, and evaluation process.","Document and catalog all TGI-deployed models with complete metadata including model ID, version, training data sources, fine-tuning parameters, quantization settings, and deployment configuration in a centralized inventory.","GOVERN-1.6 (Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities); GOVERN-1.2 (The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices)",Model Documentation; System Inventory,Model documentation completeness; Inventory accuracy; Documentation update frequency,Documented attributes / Required attributes per model. Inventory matches actual deployments / Total models. Documentation updates per period / Expected update frequency,NO,,,,,
TGI-GOV-SYS-TRANS-001,Document TGI Inference System Architecture and Purpose,Deployment,Governance,Lack of system transparency,Insufficient documentation of the system that uses the model and the model's purpose within the system in which it is used.,"Maintain comprehensive documentation of TGI deployment architecture, including system diagrams, data flows, failure modes, API interfaces, and intended use cases to enable transparency and risk assessment.",GOVERN-1.4 (The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities),System Documentation; Risk Assessment,Architecture documentation completeness; Data flow mapping coverage; Use case documentation rate,Documented system components / Total components. Data flows documented / Total flows. Use cases documented / Total deployments,NO,,,,,
TGI-TRAIN-TRANS-001,Document Training Data Sources and Preprocessing for Fine-tuned Models,Training Data,Transparency,Lack of training data transparency,"Without accurate documentation on how a model's data was collected, curated, and used to train a model, it might be harder to satisfactorily explain the behavior of the model.","When using fine-tuning support in TGI, maintain complete documentation of training data sources, preprocessing steps, filtering criteria, and data ownership for all fine-tuned model variants deployed.","GOVERN-1.6 (Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities); GOVERN-1.2 (The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices)",Data Documentation; Training Transparency,Training data documentation completeness; Data source traceability; Preprocessing documentation rate,Documented data attributes / Required attributes. Data sources traceable to original / Total data elements. Preprocessing steps documented / Total fine-tuned models,NO,,,,,
TGI-GOV-TEST-001,Establish Multi-Disciplinary Testing Framework for TGI Deployments,Deployment,Governance,Lack of testing diversity,"AI model risks are socio-technical, so their testing needs input from a broad set of disciplines and diverse testing practices.","Implement comprehensive testing across accuracy, fairness, robustness, safety, and explainability dimensions using TGI monitoring dashboards, with documented test cases covering edge cases and diverse scenarios.","GOVERN-1.4 (The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities); MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable)",Test Coverage; Risk Assessment,Test dimension coverage; Test case diversity score; Critical edge case coverage rate,Risk dimensions tested / Total dimensions. Unique test scenarios / Total tests. Edge cases covered / Identified critical cases,NO,,,,,
TGI-INF-DRIFT-001,Monitor Input Data Distribution for Drift Detection,Inference,Accuracy,Model performance degradation,Model performance may degrade over time due to data drift or distribution shifts in input data.,"Configure Prometheus metrics and Grafana dashboards to track input token distribution, prompt length patterns, and request characteristics in TGI, enabling detection of distribution shifts that may impact model performance.",MEASURE-2.2 (Evaluations involving human subjects meet applicable requirements and are representative of the relevant population); MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable),Data Drift Detection; Performance Monitoring,Distribution monitoring coverage; Drift detection latency; Data drift incident rate,Input characteristics monitored / Total characteristics. Time to detect drift / Total drift events. Count significant drifts / Total monitoring periods,YES,Drift Detection Sensitivity (%),>95%,Ensure Data Drift Detection Sensitivity Above Threshold,Data drift detection catches 95% of significant distribution shifts,Data Quality Monitoring
TGI-GOV-ACCESS-001,Implement Role-Based Access Control for TGI Endpoints,Deployment,Governance,Insufficient access control,Inadequate role-based access control for inference endpoints may allow unauthorized access or misuse.,"Configure authentication and role-based access control for all TGI inference endpoints using Protected endpoint tier with Hugging Face token authentication, mapping user roles to endpoint access permissions.","GOVERN-1.1 (Legal and regulatory requirements involving AI are understood, managed, and documented); GOVERN-1.4 (The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities)",Access Control; Identity Management,RBAC implementation rate; Authentication success rate; Unauthorized access attempt rate,Endpoints with RBAC / Total endpoints. Authenticated requests / Total requests. Blocked unauthorized access / Total access attempts,NO,,,,,
TGI-INF-CONTEXT-001,Enforce Maximum Context Length Limits,Inference,Robustness: prompt attacks,Context overload attack,Overloading the prompt with excessive tokens can predispose models to a vulnerable state.,"Configure maximum context window and prompt length limits in TGI inference parameters to prevent context overload attacks, rejecting requests exceeding safe thresholds with appropriate error messages.",MEASURE-2.5 (The AI system to be deployed is demonstrated to be valid and reliable),Input Validation; Attack Prevention,Context length limit enforcement rate; Oversized request rejection rate; Performance impact from limit enforcement,Requests validated against limits / Total requests. Oversized requests rejected / Total requests. Latency with limits / Baseline latency,YES,Context Limit Enforcement Rate (%),100%,Ensure Context Overload Attack Prevention Rate at Threshold,Context length enforcement prevents 100% of overload attacks,Input Validation
