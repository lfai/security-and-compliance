Rule ID,Lifecycle Stage,Main Risk,Sub Risk,Rule Title,Rule Description,Rationale,Implementation Guidance,Audit Procedure,NIST AI RMF Categories,Metrics to Track (Original),HF Corresponding Metrics,Threshold-Based Rule,Metric Name,Threshold Value,Threshold Direction
MLF-TRAIN-001,Training data,Accuracy,Data contamination,Implement data validation logging in MLflow tracking,"Configure MLflow tracking to log dataset validation metadata and checksums for all training runs. Track data sources, collection dates, and validation results to ensure training data integrity and prevent contamination.","Data contamination occurs when training data includes test/validation data or misaligned samples, skewing model accuracy. Logging validation results enables detection and ensures data quality.","Create custom callbacks in MLflow tracking to log: dataset_checksum, data_split_validation_status, source_verification_result. Use mlflow.log_param() for source details and mlflow.log_metrics() for validation scores. Store validation report as artifact.",Review run history for data_contamination_check metrics. Verify all runs have validation status logged. Check artifacts for validation reports. Test with known-contaminated dataset to verify detection.,MEASURE-2.2; GOVERN-1.1,Data validation logged percentage; Dataset checksum verification rate; Data contamination detection incidents; Validation error rate,Data completeness %; Missing data rate; Duplicate record percentage,Ensure data validation logged percentage >= 95%,Data Validation Logged Percentage,95%,>=
MLF-TRAIN-002,Training data,Accuracy,Unrepresentative data,Track data distribution metrics in MLflow experiments,"Log dataset statistics and distribution metrics in MLflow experiments. Track population demographics, coverage metrics, and representativeness scores. Enable comparison across runs to identify data representation issues.",Unrepresentative training data causes models to underperform for certain population groups. Tracking distribution metrics enables identification of coverage gaps.,"Log distribution metrics: demographic_coverage_ratio, underrepresented_groups_count, coverage_gap_percentage. Use mlflow.log_metrics() for ratios and mlflow.log_dict() for group-level analysis. Store distribution analysis as artifact.",Query experiment runs for distribution metrics. Identify underrepresented groups (coverage < 5%). Verify metrics are comparable across runs. Check artifact for detailed analysis. Calculate coverage trends over time.,MEASURE-2.2; GOVERN-1.4,Coverage metrics logged; Distribution analysis logged; Underrepresented segment alerts; Coverage gap percentage,Class balance ratio; Feature distribution variance; Sample coverage %,Ensure class balance ratio is between 0.9 and 1.1 (within 10% of ideal),Class Balance Ratio,0.9-1.1,within range
MLF-DATA-001,Training data,Data laws,Data acquisition restrictions,Document data licensing in MLflow artifact metadata,"Store data source licensing, acquisition method, and legal restrictions as MLflow tags and parameters for every run. Enable filtering by compliance status in UI and API.",Legal restrictions on data acquisition vary by jurisdiction and use case. Documenting licensing ensures compliance with laws and prevents legal violations.,"Add MLflow tags: data_source_license, data_acquisition_method, geographic_restriction, restricted_use_cases. Use mlflow.set_tag() to store for each run. Create tag-based search indices.",Sample 50 runs. Verify all have license tags. Verify restricted_use_cases matches actual use. Check geographic restrictions match deployment region. Review tag values for consistency.,GOVERN-1.1; GOVERN-1.2,Data source licensing compliance rate; Metadata completeness score; Legal restriction violation incidents; Restricted data incidents,License compliance score; Documented restrictions count,Ensure license compliance score is 100%,License Compliance Score,100%,=
MLF-DATA-002,Training data,Data laws,Data transfer restrictions,Enforce and log data residency policies,Configure MLflow backend storage with geographic restrictions. Log data processing location and storage region for each run. Prevent artifacts from crossing regional boundaries.,Data transfer restrictions limit cross-border movement of data. Enforcement prevents legal violations and regulatory non-compliance.,"Configure MLflow artifact store with regional restrictions. Log tags: processing_region, artifact_storage_region, cross_region_transfer_allowed. Implement backend storage access control by region.",Verify artifact store configuration enforces regional boundaries. Review tags for all runs. Check logs for any cross-region transfer attempts. Test access control by region.,GOVERN-1.1; GOVERN-1.4,Data localization compliance rate; Cross-border transfer violations; Geographic compliance audit pass rate; Transfer violation count,Geographic scope compliance; Data origin verification score,Ensure geographic scope compliance is 100%,Geographic Scope Compliance,100%,=
MLF-DATA-003,Training data,Data laws,Data usage restrictions,Implement use-case validation in MLflow run parameters,Require specification of intended use case in MLflow experiment and run parameters. Log restrictions and validate compatibility before run completion. Enable compliance audits through run history.,Some data licenses restrict usage to specific purposes. Enforcing use-case validation prevents license violations.,"Require mlflow.log_param('intended_use_case', value) in all training scripts. Validate against allowed_use_cases list. Log validation_status metric. Implement pre-run validation hooks.",Query runs for intended_use_case parameter. Verify all runs have this set. Check validation_status for all. Audit runs with restricted use cases. Verify compliance history.,GOVERN-1.1; GOVERN-1.2,Usage restriction compliance rate; Policy violation incidents; Validation success rate; Unauthorized usage incidents,Use case alignment score; Scope mismatch incidents,Ensure use case alignment score is 100%,Use Case Alignment Score,100%,=
MLF-FAIR-001,Training data,Fairness,Data bias,Log bias metrics and demographic parity in experiments,"Define and log fairness metrics (statistical parity, demographic parity) in MLflow experiments. Track across demographic groups. Create alerts for significant disparities between runs.",Biased training data perpetuates and amplifies existing biases. Tracking fairness metrics enables early detection and mitigation.,"Log metrics: demographic_parity_ratio, statistical_parity_diff, equal_opportunity_diff for each demographic group. Use mlflow.log_metrics() with group prefixes. Create comparison plots.",Query experiments for fairness metrics. Calculate parity differences (target < 5%). Identify groups with largest disparities. Review trending across runs. Compare models on fairness.,MEASURE-2.11; GOVERN-1.2,Demographic parity score; Statistical parity tracking; Bias alert incidents; Disparity percentage,Demographic Parity Ratio; Statistical Parity Diff; Equalized Odds Difference,Ensure demographic parity ratio difference is <= 5%,Demographic Parity Ratio Difference,5%,<=
MLF-IP-001,Training data,Intellectual property,Confidential information in data,Screen and tag sensitive data sources in MLflow,Implement MLflow custom metrics for PII/confidential data scanning. Log detection results and redaction status as metrics. Tag runs with sensitivity level.,Including confidential data in training can lead to unwanted disclosure in model outputs. Screening prevents information leakage.,"Log metrics: pii_elements_detected, confidential_patterns_found, redaction_success_rate. Tag runs with sensitivity_level (high/medium/low). Store detection report as artifact.",Review PII detection metrics for all runs. Verify redaction_success_rate > 99%. Check sensitivity_level tags. Audit runs with high PII count. Verify redaction artifacts.,GOVERN-1.1; GOVERN-1.2,Confidential data detection rate; Redaction success; Sensitive data incidents; Detection coverage,PII Detection Rate; Confidential Pattern Match Count,Ensure PII detection rate is >= 95%,PII Detection Rate,95%,>=
MLF-IP-002,Training data,Intellectual property,Data usage rights restrictions,Validate and document license compliance in experiments,Log license types for all data sources as MLflow tags. Implement validation logic to check compliance before run registration. Store license audit trail.,License compliance prevents legal liability and IP violations. Documentation enables audit and compliance verification.,"Add tags: license_type, license_commercial_restriction, license_restriction_applies. Implement pre-run license validation. Log validation_status metric. Store license audit trail.",Sample runs and verify license_type tags. Check validation_status for compliance. Test validation logic with incompatible licenses. Review audit trail for changes.,GOVERN-1.1; GOVERN-1.2,License compliance rate; Validation pass rate; IP violation incidents; Non-compliance incident count,License Compliance Score; Incompatible License Count,Ensure license compliance rate is 100%,License Compliance Rate,100%,=
MLF-PRIV-001,Training data,Privacy,Personal information in data,Log PII detection and redaction metrics,"Use MLflow metrics to track PII detection, redaction success, and retention status. Store detection results and redaction rules as artifacts. Enable compliance audits.",PII in training data can lead to unwanted disclosure. Tracking detection and redaction ensures privacy protection.,"Log metrics for each PII type: email_detected, ssn_detected, phone_detected, credit_card_detected, redaction_success_rate. Store PII summary in artifact. Tag sensitivity.",Review PII metrics for all training runs. Verify redaction_success_rate > 99%. Check redaction artifacts. Audit unredacted PII incidents. Verify privacy compliance.,GOVERN-1.1; GOVERN-1.2,PII detection rate; Redaction success rate; Unredacted PII incidents; Detection accuracy > 99%,PII Detection Rate; Redaction Success Rate; Unredacted PII Incidents,Ensure redaction success rate is >= 99%,Redaction Success Rate,99%,>=
MLF-PRIV-002,Training data,Privacy,Data privacy rights alignment,Maintain data provenance in MLflow registry for deletion,Store data provenance and source attribution in MLflow model tags and metadata. Enable tracking of data sources to support right-to-deletion requests through model lineage.,Supporting data subject rights (right-to-deletion) requires tracking data sources. Model provenance enables efficient deletion workflows.,"Store in model tags: training_data_sources, collection_dates, data_subject_ids (if applicable). Link model to training run with full provenance. Enable lineage queries.",Review registered models for provenance tags. Verify complete source tracking. Test lineage traversal from model to data. Verify deletion capability through tags.,GOVERN-1.1; GOVERN-1.2,Provenance documentation completeness; Deletion request fulfillment rate; Lineage accuracy; Traceability score,Provenance Documentation Completeness %; Deletion Request Fulfillment Rate,Ensure provenance documentation completeness is >= 95%,Provenance Documentation Completeness,95%,>=
MLF-PRIV-003,Training data,Privacy,Reidentification,Track quasi-identifier correlation metrics,Log correlation analysis of sensitive features in MLflow metrics. Track quasi-identifiers and flag high-correlation patterns. Document privacy protection measures.,High correlation between quasi-identifiers and PII can enable reidentification attacks even with anonymization. Tracking correlation prevents reidentification.,"Log metrics: quasi_identifier_count, max_correlation_score, feature_combinations_risky. Store correlation matrix as artifact. Flag dangerous combinations.",Review correlation metrics for all runs. Identify high-correlation features (> 0.7). Check for risky feature combinations. Verify privacy protection status. Test reidentification resistance.,GOVERN-1.1; GOVERN-1.2,Reidentification risk score; Correlated feature count; Privacy protection rating; Risk level classification,Max Feature Correlation Score; Reidentification Risk Rating,Ensure max feature correlation score is <= 0.7,Max Feature Correlation Score,0.7,<=
MLF-ROB-001,Training data,Robustness,Data poisoning,Implement integrity checks and log validation results,"Log data integrity validation (checksum, signature verification) results in MLflow. Store validation reports as artifacts. Flag any integrity failures.",Data poisoning attacks inject malicious data to compromise model training. Integrity checks prevent model poisoning.,"Log metrics: checksum_validation_pass_rate, signature_verification_success, poisoned_data_detected. Store validation report as artifact. Flag failed checks.",Review checksum_validation metrics for all runs. Verify > 99% pass rate. Test with known poisoned data. Check artifact reports. Audit failed validations.,MEASURE-2.5; GOVERN-1.1,Checksum validation pass rate; Signature verification success; Poisoned data detection rate; Integrity failure incidents,Checksum Validation Pass Rate; Data Integrity Score,Ensure checksum validation pass rate is >= 99.9%,Checksum Validation Pass Rate,99.9%,>=
MLF-INF-001,Inference,Accuracy,Poor model accuracy,Enable performance monitoring through MLflow models,Register models with documented performance expectations in tags. Log baseline accuracy metrics. Create model version aliases for performance tiers.,Poor model accuracy indicates insufficient testing or performance degradation. Baseline tracking enables detection.,"Tag models: baseline_accuracy, minimum_acceptable_accuracy, accuracy_threshold_warning. Create aliases: champion, challenger for performance tiers.",Review baseline_accuracy tags for models. Compare current performance vs. baseline. Verify models meet minimum_acceptable_accuracy. Check aliases for performance classification.,MEASURE-2.2; GOVERN-1.4,Model accuracy tracking; Performance baseline compliance; Version monitoring rate; Accuracy violation incidents,Accuracy; Precision; Recall; F1 Score; AUC-ROC,Ensure model accuracy is >= baseline - 2%,Model Accuracy vs Baseline,baseline - 2%,>=
MLF-PROM-001,Inference,Intellectual property,Confidential data in prompt,Log input sanitization metrics in MLflow tracing,Use MLflow tracing to log PII/confidential data detection in inputs. Track sanitization events and outcomes. Store detection summaries as metrics.,Confidential data in prompts can be leaked in outputs. Input filtering prevents data exposure.,"Enable MLflow tracing. Log context: confidential_data_detected, sanitization_applied, data_type. Store detection summary in trace attributes.",Query traces for confidential_data_detected. Verify sanitization_applied for detections. Check for exposure incidents. Audit sanitization success.,GOVERN-1.1; GOVERN-1.2,Input sanitization success; Confidential data detection rate; Exposure incidents; Detection coverage,Input Sanitization Success Rate; Confidential Data Detection Rate,Ensure input sanitization success rate is >= 95%,Input Sanitization Success Rate,95%,>=
MLF-PROM-002,Inference,Privacy,Personal information in prompt,Track PII handling in MLflow trace logs,Log PII detection and masking in MLflow trace context. Track PII types detected and redaction applied. Store redaction statistics as trace metrics.,PII in prompts risks unwanted disclosure. Tracking redaction ensures privacy protection.,"Log trace metrics: pii_detected, redaction_applied, pii_types_found. Store redaction details in trace context. Create trace-level audit.",Query traces for pii_detected. Verify redaction_applied for all. Check PII types. Audit redaction success. Verify privacy compliance.,GOVERN-1.1; GOVERN-1.2,PII detection rate in inputs; Redaction success; PII exposure incidents; Coverage percentage,Input PII Detection Rate; Redaction Success; PII Exposure Incidents,Ensure input PII detection rate is >= 95%,Input PII Detection Rate,95%,>=
MLF-ROBUST-001,Inference,Robustness: prompt attacks,Prompt injection attack,Log injection attack detection in MLflow traces,Use MLflow tracing to capture and log detected injection patterns. Log payload analysis results. Store threat signals as trace metrics for monitoring.,Prompt injection attacks manipulate model behavior. Detection enables defense and incident response.,"Log trace metrics: injection_pattern_detected, attack_probability, payload_type. Store threat analysis in trace context. Create detection alert.",Query traces for injection_pattern_detected. Review high-probability detections. Check threat analysis. Audit incident response. Verify detection accuracy.,MEASURE-2.5; GOVERN-1.1,Injection detection rate; Attack prevention success; Incident frequency; False positive rate,Injection Attack Detection Rate; Attack Prevention Success,Ensure injection attack detection rate is >= 95%,Injection Attack Detection Rate,95%,>=
MLF-ROBUST-002,Inference,Robustness: prompt attacks,Direct instructions attack,Monitor output safety through MLflow metrics,Log safety classification results for outputs in MLflow traces. Track harmful content detection and filtering events. Create metrics dashboard.,Direct attacks elicit harmful responses. Output filtering prevents harm.,"Log trace metrics: harmful_content_detected, safety_score, filter_applied. Store content classification in trace. Create safety metrics dashboard.",Query traces for harmful_content_detected. Verify filter_applied for all. Check safety_score distribution. Audit safety violations. Review filtering effectiveness.,MEASURE-2.5; GOVERN-1.2,Harmful content detection; Filter effectiveness; Safety violation incidents; Coverage rate,Harmful Content Detection Rate; Output Filter Effectiveness,Ensure harmful content detection rate is >= 99%,Harmful Content Detection Rate,99%,>=
MLF-ROBUST-003,Inference,Robustness: prompt attacks,Prompt leaking,Detect and log extraction attacks in traces,Log suspicious queries attempting prompt extraction. Track pattern-matching results. Alert on extraction attempt patterns via MLflow metrics.,Prompt leaking extracts sensitive system information. Detection enables defense.,"Log trace metrics: extraction_attempt_detected, suspicious_pattern_score, extraction_probability. Store threat details in trace. Alert on high probability.",Query for extraction_attempt_detected metrics. Review high-probability attempts. Check response handling. Audit incident log. Verify detection accuracy.,MEASURE-2.5; GOVERN-1.1,Extraction attempt detection; Attack prevention; Incident frequency; False positive rate,Extraction Attempt Detection Rate; Attack Prevention Rate,Ensure extraction attack prevention rate is >= 95%,Extraction Attack Prevention Rate,95%,>=
MLF-ROBUST-004,Inference,Robustness: model behavior manipulation,Jailbreaking,Log behavioral anomalies in inference traces,Use MLflow tracing to capture behavioral anomalies. Log policy violation patterns. Create behavioral baseline metrics for alerting.,Jailbreaking bypasses safety constraints. Behavioral monitoring detects attacks.,"Log trace metrics: behavior_anomaly_detected, policy_violation_probability, deviation_from_baseline. Store anomaly details. Alert on threshold breach.",Query for behavior_anomaly_detected. Review anomaly descriptions. Check baseline deviation. Audit incident response. Verify detection accuracy.,MEASURE-2.5; GOVERN-1.2,Anomaly detection rate; Policy violation incidents; Escalation frequency; False positive rate,Behavioral Anomaly Detection Rate; Policy Violation Incidents,Ensure behavioral anomaly detection rate is >= 90%,Behavioral Anomaly Detection Rate,90%,>=
MLF-EXPLAIN-001,Output,Explainability,Unexplainable output,Log and store model explanations as artifacts,Store LIME/SHAP explanation artifacts for model predictions. Log explanation metrics in MLflow. Enable explanation comparison across model versions.,Unexplainable outputs are difficult to debug and trust. Explanations enable understanding and trust.,Compute LIME/SHAP explanations. Store as artifact. Log explanation_coverage and explanation_quality_score metrics. Enable version comparison.,Verify explanation artifacts for sample predictions. Check explanation_coverage > 95%. Review explanation quality. Compare across versions.,MEASURE-2.13; GOVERN-1.4,Explanation generation success; Output coverage; Clarity score; User understanding metrics,Explanation Generation Success Rate; Output Coverage %,Ensure explanation coverage is >= 95%,Explanation Coverage,95%,>=
MLF-EXPLAIN-002,Output,Explainability,Unreliable source attribution,Track and validate source citations in traces,Log source documents used in predictions in MLflow traces. Validate citation accuracy. Store citation reports as artifacts.,Incorrect source attribution misleads users. Validation ensures citations are accurate.,"Log trace context: source_documents_used, citation_count, validation_status. Store citation report artifact. Validate citations against sources.",Query traces for source_documents_used. Sample citations and verify accuracy. Check validation_status. Audit hallucinated sources. Report citation accuracy.,MEASURE-2.13; GOVERN-1.4,Source attribution accuracy; Citation verification rate; Hallucination incidents; Coverage percentage,Source Attribution Accuracy; Citation Verification Rate; Hallucination Rate,Ensure source attribution accuracy is >= 95%,Source Attribution Accuracy,95%,>=
MLF-FAIR-002,Output,Fairness,Decision bias,Monitor fairness metrics across model versions,"Log fairness metrics (parity, equal opportunity) by demographic group in MLflow. Compare across model versions. Create fairness dashboards.",Biased outputs harm disadvantaged groups. Fairness monitoring enables detection and mitigation.,"Log trace metrics for each demographic: statistical_parity, equal_opportunity_diff, disparity_ratio. Store demographic analysis. Create comparison plots.",Query traces for fairness metrics by group. Calculate disparity ratios (target < 5%). Identify largest disparities. Review model comparison. Audit trends.,MEASURE-2.11; GOVERN-1.2,Statistical parity ratio; Demographic disparity; Fairness violation incidents; Disparity percentage,Statistical Parity Ratio; Equal Opportunity Difference; Disparate Impact Ratio,Ensure statistical parity ratio difference is <= 5%,Statistical Parity Ratio Difference,5%,<=
MLF-FAIR-003,Output,Fairness,Output bias,Log bias detection results in production traces,Use MLflow tracing to detect and log biased output patterns. Track by demographic dimension. Create alerts for significant bias.,Biased generated content harms users and perpetuates discrimination. Detection enables mitigation.,"Log trace metrics: bias_detected, bias_type (stereotyping/underrepresentation), demographic_affected. Store bias analysis. Alert on threshold.",Query traces for bias_detected. Categorize by bias type and demographic. Identify flagged outputs. Audit bias incidents. Track trends.,MEASURE-2.11; GOVERN-1.2,Bias detection rate; Demographic representation score; Flagged content percentage; Incident tracking,Bias Detection Rate; Demographic Representation Score; Flagged Content %,Ensure bias detection rate is >= 95%,Bias Detection Rate,95%,>=
MLF-OUT-IP-001,Output,Intellectual property,Revealing confidential information,Log confidential information detection in outputs,Use MLflow tracing to detect leakage of confidential patterns in outputs. Track and log all detections. Store sanitization results.,Confidential data leakage violates IP rights and creates legal liability. Detection prevents disclosure.,"Log trace metrics: confidential_data_detected, leakage_probability, data_type. Store detection details. Track sanitization applied.",Query traces for confidential_data_detected. Review detections and types. Check sanitization. Audit leakage incidents. Verify prevention.,GOVERN-1.1; GOVERN-1.2,Confidential data detection; Filter success rate; Leakage incidents; Detection accuracy,Confidential Data Detection in Output; Leakage Incidents,Ensure confidential data detection in output is >= 90%,Output Confidential Data Detection,90%,>=
MLF-HALL-001,Output,Robustness,Hallucination,Track hallucination metrics in evaluation experiments,Log hallucination detection results in MLflow experiments. Track factuality grounding scores. Store hallucination analysis as artifacts.,Hallucinations generate false information. Tracking enables identification and mitigation.,"Log metrics: hallucination_detected, grounding_score, factuality_check_passed. Store hallucination analysis artifact. Track by output type.",Query experiment runs for hallucination_detected. Check grounding_score distribution. Review hallucination analysis artifacts. Identify hallucination patterns.,MEASURE-2.5; GOVERN-1.4,Hallucination detection rate; Grounding score; False information incidents; Coverage percentage,Hallucination Detection Rate; Grounding Score; Factuality Verification Rate,Ensure hallucination detection rate is >= 95%,Hallucination Detection Rate,95%,>=
MLF-HARM-001,Output,Value alignment,Harmful output,Log safety filter results in production traces,Use MLflow tracing to log harmful content detection and filtering. Track by harm type. Create safety dashboards and alerts.,Harmful outputs cause direct harm to users. Filtering prevents harm.,"Log trace metrics: harmful_content_detected, harm_type (violence/abuse/etc), filter_applied. Store harm analysis. Alert on incidents.",Query traces for harmful_content_detected. Categorize by harm type. Verify filter_applied. Audit safety violations. Review incident response.,GOVERN-1.2; MEASURE-2.5,Harmful content detection; Filter effectiveness; Safety incidents; Detection accuracy,Harmful Content Detection Rate; Filter Effectiveness; Safety Incidents,Ensure harmful content detection rate is >= 99%,Harmful Content Detection Rate,99%,>=
MLF-TOXIC-001,Output,Value alignment,Toxic output,Monitor toxicity scores in MLflow traces,Log toxicity classification results in MLflow traces. Track by toxicity type. Store statistics as metrics for monitoring.,Toxic output harms users and damages trust. Monitoring enables detection.,"Log trace metrics: toxicity_score, toxicity_type (insult/threat/profanity), toxicity_level. Store statistics. Create toxicity dashboard.",Query traces for toxicity_score. Review score distribution. Identify high-toxicity outputs. Track by toxicity type. Audit trends.,GOVERN-1.2; MEASURE-2.5,Toxicity score distribution; Toxic content percentage; Incident tracking; Detection accuracy,Toxicity Detection Rate; Toxic Content Percentage; Severity Classification,Ensure toxicity detection rate is >= 98%,Toxicity Detection Rate,98%,>=
MLF-GOV-001,Non-technical,Governance,Lack of model transparency,Maintain complete model metadata in registry,"Require comprehensive metadata in model registry: version info, purpose, capabilities, limitations, performance metrics. Store as tags and descriptions. Enable model discovery.",Incomplete documentation makes models difficult to evaluate and reuse. Complete metadata enables discovery and audit.,"Require tags: model_purpose, model_capabilities, model_limitations, performance_metrics, owner, creation_date. Store detailed description. Enable tag-based search.",Sample registered models. Verify all required tags present. Review descriptions for completeness. Test model discovery by tags. Verify metadata accuracy.,GOVERN-1.6; GOVERN-1.4,Documentation completeness; Metadata quality score; Discovery effectiveness; Update frequency,Documentation Completeness %; Metadata Quality Score,Ensure documentation completeness is >= 100%,Documentation Completeness,100%,>=
MLF-GOV-002,Non-technical,Governance,Incorrect risk testing,Standardize evaluation metrics in MLflow experiments,Define and log standardized evaluation metrics for all models in MLflow. Document risk-metric mappings. Enable automated testing through experiment tracking.,Non-standardized metrics make results incomparable. Standard metrics enable consistent risk assessment.,"Define metric set: accuracy, precision, recall, F1, fairness_metrics, bias_metrics. Log all for every experiment. Document risk-metric mapping. Implement automated checks.",Query experiments for metric completeness. Verify all standard metrics logged. Check risk-metric mapping documentation. Verify automated checks run. Audit metric results.,GOVERN-1.3; GOVERN-1.4,Risk test coverage; Metric standardization rate; Test automation percentage; Compliance rate,Metric Standardization Rate; Risk Test Coverage; Benchmark Compliance,Ensure metric standardization rate is >= 100%,Metric Standardization Rate,100%,>=
MLF-STAGE-001,Non-technical,Governance,Uncontrolled model promotion,Implement stage transition validation in model registry,Enforce validation gates for model stage transitions (Staging -> Production). Log stage change rationale and approver. Track stage duration and rollback events.,Uncontrolled promotion risks deploying poor models. Validation gates ensure quality.,"Require tags for transition: validation_status, approver_id, approval_date, transition_rationale. Implement validation hooks before transition. Log all transitions.",Review model stage history. Verify validation_status for all transitions. Check approver documentation. Audit transitions without validation. Track rollback events.,GOVERN-1.1; GOVERN-1.4,Validation gate pass rate; Unauthorized promotion attempts; Stage transition audit log; Rollback incidents,Validation Gate Pass Rate; Unauthorized Promotion Attempts,Ensure validation gate pass rate is >= 100%,Validation Gate Pass Rate,100%,>=
MLF-STAGE-002,Non-technical,Governance,Insufficient model versioning,Enforce versioning discipline in model registry,Require semantic versioning for registered models. Store version changelog and artifacts. Enable quick rollback through version management.,Poor versioning makes rollback difficult and tracking error sources hard. Semantic versioning enables efficient management.,Require version format: MAJOR.MINOR.PATCH. Store changelog as tag. Archive all version artifacts. Enable version-based rollback.,Verify all models use semantic versioning. Check changelog for all versions. Test rollback capability. Audit version artifact retention.,GOVERN-1.6; GOVERN-1.4,Versioning compliance rate; Version lifecycle tracking; Rollback success rate; Artifact retention,Versioning Compliance Rate; Version Lifecycle Tracking; Rollback Success Rate,Ensure versioning compliance rate is >= 100%,Versioning Compliance Rate,100%,>=
MLF-EXP-001,Non-technical,Governance,Poor experiment documentation,Require comprehensive experiment logging,"Mandate logging of code version, data version, parameters, and results for all experiments. Store experiment purpose and owner. Enable experiment comparison and reproducibility.",Poor documentation prevents reproducibility and understanding of results. Complete logging enables analysis.,"Log params: code_version, data_version, experiment_purpose, owner. Log all parameters and metrics. Store source code as artifact. Document methodology.",Sample experiments. Verify all required params. Check artifact for source code. Review documentation completeness. Test reproducibility.,GOVERN-1.6; GOVERN-1.4,Experiment logging completeness; Parameter documentation rate; Reproducibility score; Coverage percentage,Experiment Logging Completeness %; Parameter Documentation Rate; Reproducibility Score,Ensure experiment logging completeness is >= 100%,Experiment Logging Completeness,100%,>=
MLF-EXP-002,Non-technical,Governance,Reproducibility issues,Enforce reproducibility through artifact and metadata logging,"Log all dependencies, data versions, and random seeds in MLflow. Store data samples and transformations as artifacts. Enable perfect reproducibility checks.",Non-reproducible experiments prevent debugging and trust. Complete logging enables reproduction.,"Log params: random_seed, python_version, dependency_versions. Store data samples as artifacts. Log transformation steps. Enable reproducibility verification.",Sample runs and collect all logged info. Attempt re-run with logged params. Verify identical results. Check artifact completeness. Audit reproducibility success.,GOVERN-1.4; GOVERN-1.1,Reproducibility score; Dependency tracking; Artifact completeness; Re-run success rate,Reproducibility Score; Dependency Version Tracking; Re-run Success Rate,Ensure reproducibility score is >= 90%,Reproducibility Score,90%,>=
MLF-ART-001,Non-technical,Privacy,Artifacts containing sensitive data,Scan and sanitize artifacts before storage,Implement artifact scanning for PII before storage in MLflow backend. Log detection and sanitization results. Enforce artifact encryption for sensitive content.,Artifacts may contain PII or sensitive data. Sanitization prevents unwanted exposure.,"Implement artifact scanner: detect PII, secrets, credentials. Log detection results. Apply encryption for sensitive artifacts. Store scan report.",Sample stored artifacts. Verify scan results. Check for undetected PII. Verify encryption on sensitive artifacts. Audit scan coverage.,GOVERN-1.1; GOVERN-1.2,Artifact scan success rate; PII detection rate; Sanitization coverage; Encryption compliance,Artifact Scan Success Rate; PII Detection in Artifacts; Encryption Compliance,Ensure artifact scan success rate is >= 100%,Artifact Scan Success Rate,100%,>=
MLF-TRACE-001,Inference,Governance,Insufficient execution visibility,Enable comprehensive tracing for all framework integrations,"Use MLflow tracing auto-logging for all GenAI frameworks (LangChain, OpenAI, LlamaIndex, etc.). Log all inputs, outputs, and parameters. Create searchable trace index.","Without complete execution traces, debugging and auditing are difficult. Comprehensive tracing enables investigation.","Enable mlflow.openai.autolog(), mlflow.langchain.autolog(), etc. Log all framework calls. Store traces in searchable format. Create trace search UI.",Verify auto-logging enabled for all frameworks in use. Sample traces for completeness. Verify searchability. Test trace retrieval. Audit coverage.,GOVERN-1.6; GOVERN-1.4,Tracing coverage; Trace completeness; Query effectiveness; Searchability index,Tracing Coverage %; Trace Completeness Score; Framework Coverage,Ensure tracing coverage is >= 100%,Tracing Coverage,100%,>=
MLF-TRACE-002,Inference,Governance,Incomplete audit trail,Maintain immutable audit trail through trace logging,Enable MLflow trace persistence and immutability. Log all execution parameters and decisions. Store traces in append-only format for compliance.,Mutable audit trails can be tampered with. Immutability ensures legal admissibility and audit validity.,Enable trace persistence. Configure append-only storage backend. Log all parameters and decisions. Lock traces after completion. Verify immutability.,Verify trace persistence enabled. Sample traces and verify immutability. Attempt trace modification (should fail). Check append-only backend. Audit compliance.,GOVERN-1.6; GOVERN-1.1,Audit trail completeness; Immutability verification; Compliance status; Integrity score,Audit Trail Completeness %; Immutability Verification; Regulatory Compliance Score,Ensure audit trail completeness is >= 100%,Audit Trail Completeness,100%,>=
