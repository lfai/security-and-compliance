Risk Lifecycle,Main Risk,Sub Risk Title,Sub Risk Description,Rule ID,Rule Title,Rule Description,NIST AI RMF Sub Categories,Metric/Parameter/Topic,Metric Calculation Description,HuggingFace_Model_Card_Metric,Metric_Threshold_Value,Threshold_Unit,Metric-based_Rule_Form,Rule_Status
Training data,Accuracy,Data contamination,Data contamination occurs when incorrect data is used for training.,HFT-001,Implement dataset verification in training pipeline,Implement verification checks in the Transformers training pipeline to ensure training data does not overlap with test/validation sets. Use DataCollatorWithPadding and custom dataset classes to validate data split integrity before model training.,MEASURE-2.2; MEASURE-2.5,Data overlap percentage; Train-test separation ratio,Calculate percentage of samples appearing in multiple splits using dataset hashing; verify no common samples exist between training and validation datasets,Procedural rule - training pipeline implementation,,,,SKIPPED
Training data,Accuracy,Unrepresentative data,Training data not sufficiently representative of the underlying population.,HFT-002,Enable dataset analysis and stratification,"Utilize Transformers with custom data loaders to implement stratified sampling and dataset analysis. Document data demographics and representativeness through model card metadata fields (datasets, metrics, tags).",MEASURE-2.2; GOVERN-1.6,Class balance ratio; Dataset coverage metrics; Demographic representation percentage,Calculate ratio of minority/majority classes in training set; measure percentage of demographic groups represented; compute coverage of expected input distribution,Class Balance Ratio,0.8,Ratio,Ensure Class Balance Ratio is >= 0.80,MAPPED
Training data,Fairness,Data bias,Historical and societal biases present in training data.,HFT-003,Implement bias detection and mitigation in preprocessing,"Use Transformers with Evaluate library bias metrics (statistical parity, equal opportunity, predictive parity) to detect and document training data biases. Include bias analysis in model cards and documentation.",MEASURE-2.11; GOVERN-1.2,Statistical parity difference; Equal opportunity difference; Predictive parity metrics,Compare prediction rates across demographic groups; calculate disparity index for model outcomes by protected attributes; measure bias metrics on held-out test sets,Statistical Parity Difference,0.1,Percentage Points,Ensure Statistical Parity Difference is < 0.10,MAPPED
Training data,Privacy,Data privacy rights alignment,Compliance with data privacy regulations and data subject rights.,HFT-004,Document data privacy handling and retention policies,"Use Transformers model cards to document data sources, licenses, and privacy compliance status. Implement privacy metadata fields including data retention policies, anonymization methods, and regulatory compliance status.",GOVERN-1.1; GOVERN-1.6,Privacy documentation completeness; Consent management rate; Data retention policy adherence,Verify presence of privacy sections in model card; track percentage of data with valid consent; audit alignment with stated retention policies,Procedural rule - documentation requirement,,,,SKIPPED
Training data,Privacy,Personal information in data,Inclusion of PII and sensitive personal information in training data.,HFT-005,Enable data anonymization and PII detection,Implement preprocessing steps in Transformers data pipelines to detect and mask PII. Use custom TokenClassificationPipeline to identify sensitive entities before training. Document anonymization approaches in model cards.,GOVERN-1.1,PII detection rate; Anonymization coverage percentage; Undetected PII samples,Run PII detection models on training dataset; measure percentage of identified PII that is masked/removed; track residual PII through manual audit sampling,PII Detection Rate,95,Percentage (%),Ensure PII Detection Rate is >= 95%,MAPPED
Training data,Transparency,Lack of training data transparency,"Insufficient documentation on data collection, curation, and usage.",HFT-006,Implement comprehensive dataset documentation,"Leverage Transformers model card framework (README.md with YAML metadata) to document dataset lineage, collection methodology, preprocessing steps, and known limitations. Include dataset identifiers and version control in metadata.",GOVERN-1.6; GOVERN-1.2,Documentation completeness score; Metadata field population rate; Lineage traceability,Create checklist of required documentation fields and calculate percentage completion; audit model card for dataset provenance information; verify version control implementation,Procedural rule - documentation requirement,,,,SKIPPED
Training data,Transparency,Uncertain data provenance,"Inability to verify data origin, ownership, and transformations.",HFT-007,Establish data source verification and versioning,"Use Transformers with model card system to document data sources, URLs, collection dates, and transformations applied. Implement dataset version tracking in repository metadata and configuration files.",GOVERN-1.6,Data source verification rate; Version control coverage; Transformation documentation completeness,Verify each training dataset has documented origin; check git history for data modification tracking; audit config files for data lineage information,Procedural rule - data governance requirement,,,,SKIPPED
Training data,Value alignment,Improper data curation,"Data curation includes label errors, conflicting information, or misinformation.",HFT-008,Implement data quality validation and human review,Integrate data validation steps in Transformers training pipelines. Use callbacks to log data quality metrics and require human-in-the-loop review of questionable samples. Document label quality standards in model cards.,GOVERN-1.2; MEASURE-2.5,Label agreement rate; Data quality score; Human review completion percentage,Calculate inter-annotator agreement scores for labeled data; implement quality checks on label distributions; track percentage of samples reviewed by humans,Label Agreement Rate,85,Percentage (%),Ensure Label Agreement Rate is >= 85%,MAPPED
Inference,Accuracy,Poor model accuracy,Model performance is insufficient for the intended task.,HFT-009,Monitor model accuracy with automated evaluation,Use Transformers Trainer.evaluate() and custom evaluation scripts to regularly assess model accuracy on held-out test sets. Implement automated evaluation pipelines and monitoring dashboards that track metrics over time.,MEASURE-2.2; MEASURE-2.5,Precision; Recall; F1-score; Mean absolute error,Calculate standard evaluation metrics on test set; establish baseline performance thresholds; trigger retraining when metrics fall below thresholds,F1-score,0.8,Score (0-1),Ensure F1-score is >= 0.80,MAPPED
Inference,Fairness,Output bias,Generated content unfairly represents certain groups or individuals.,HFT-010,Monitor and measure fairness metrics in model outputs,"Integrate Hugging Face Evaluate library bias metrics into inference pipelines. Log predictions by demographic groups and compute fairness metrics (demographic parity, equalized odds). Generate fairness reports for deployment decisions.",MEASURE-2.11; GOVERN-1.2,Demographic parity; Equalized odds; Calibration metrics; Fairness violation rate,Run inference on diverse test sets; segment results by protected attributes; compute disparities and flag violations when exceeding thresholds,Demographic Parity,90,Percentage (%),Ensure Demographic Parity is >= 90%,MAPPED
Inference,Fairness,Decision bias,Certain groups unfairly disadvantaged by model predictions.,HFT-011,Implement decision-level fairness monitoring,Use Transformers outputs with fairness evaluation libraries to analyze decision distributions across demographic groups. Implement thresholds for acceptable bias levels and log violations. Document fairness properties in model cards.,MEASURE-2.11,Statistical parity difference; Equalized odds difference; Impact ratio,Calculate prediction rates by demographic group; measure adverse impact ratios; monitor for statistical significance of disparities,Equalized Odds Difference,0.05,Percentage Points,Ensure Equalized Odds Difference is < 0.05,MAPPED
Inference,Robustness: model behavior manipulation,Evasion attack,Attempts to alter model behavior through input perturbations.,HFT-012,Implement robustness testing for adversarial inputs,Use Transformers models with adversarial testing frameworks to evaluate robustness against input perturbations and evasion attempts. Implement input validation and sanitization pipelines before inference.,MEASURE-2.5,Adversarial attack success rate; Robustness test pass rate; Input perturbation tolerance,Generate adversarial examples and measure model behavior changes; calculate percentage of attacks that succeed; assess model stability under input variations,Adversarial Attack Success Rate,10,Percentage (%),Ensure Adversarial Attack Success Rate is < 10%,MAPPED
Inference,Robustness: prompt attacks,Jailbreaking,Attempts to break through guardrails to trigger restricted model actions.,HFT-013,Test and enforce safety constraints in prompts,Implement prompt validation and filtering in Transformers inference pipelines. Create safety-focused test suites to detect jailbreak attempts. Document safety measures and guardrails in model cards.,MEASURE-2.5,Jailbreak attempt detection rate; Guardrail bypass success rate; Safety constraint violations,Test model with known jailbreak prompts; measure percentage detected; evaluate guardrail robustness through systematic testing,Jailbreak Attempt Detection Rate,98,Percentage (%),Ensure Jailbreak Attempt Detection Rate is >= 98%,MAPPED
Inference,Robustness: prompt attacks,Prompt injection attack,"Manipulation of prompt structure, instructions, or embedded information to produce unexpected output.",HFT-014,Implement prompt sanitization and validation,Use Transformers with input sanitization layers to detect and prevent prompt injection attacks. Implement validation rules for prompt structure and content. Log suspicious prompts for analysis.,MEASURE-2.5,Injection attempt detection rate; Prompt validation pass rate; Malicious pattern detection rate,Track prompt structure violations; measure detection sensitivity and specificity; audit false negative injection attempts,Prompt Injection Detection Rate,95,Percentage (%),Ensure Prompt Injection Detection Rate is >= 95%,MAPPED
Inference,Privacy,Attribute inference attack,Query model to infer sensitive attributes about training data subjects.,HFT-015,Monitor for membership and attribute inference attacks,Implement query logging and anomaly detection on model inference endpoints using Transformers. Monitor for suspicious patterns of repeated queries designed to extract training data information.,GOVERN-1.1,Query pattern anomaly detection rate; Repeated query clustering; Inference attack attempt percentage,Establish baseline query patterns; detect statistical anomalies; classify high-risk query sequences,Query Anomaly Detection Rate,90,Percentage (%),Ensure Query Anomaly Detection Rate is >= 90%,MAPPED
Inference,Privacy,Membership inference attack,Determine if a data sample was part of model training data.,HFT-016,Detect membership inference attacks through query monitoring,Use Transformers inference servers with query monitoring and rate limiting to detect membership inference attacks. Log confidence scores and identify suspicious query patterns targeting specific data points.,GOVERN-1.1,Membership test detection rate; Query anomaly score; Inference confidence patterns,Monitor for repeated queries on same inputs; detect confidence patterns; flag suspicious sequences,Membership Test Detection Rate,92,Percentage (%),Ensure Membership Test Detection Rate is >= 92%,MAPPED
Inference,Privacy,Personal information in prompt,PII or sensitive information included in prompts sent to the model.,HFT-017,Implement prompt-level PII detection and filtering,Use custom preprocessing layers in Transformers inference pipelines to detect PII in prompts. Implement automatic PII masking and logging of detection events. Warn users about sensitive data in queries.,GOVERN-1.1,PII detection rate in prompts; Prompt masking percentage; PII warning generation rate,Run PII detection on all incoming prompts; measure masking effectiveness; track user warnings issued,PII Detection Rate in Prompts,93,Percentage (%),Ensure PII Detection Rate in Prompts is >= 93%,MAPPED
Inference,Explainability,Unexplainable output,Difficulty obtaining clear explanations for model predictions.,HFT-018,Generate and validate model explanations,"Use Transformers with explainability libraries (LIME, SHAP, attention visualization) to generate explanations for model outputs. Validate explanation quality and consistency. Document explainability methods in model cards.",MEASURE-2.13,LIME/SHAP coverage percentage; Feature importance consistency; Explanation validation score,Generate explanations for sample predictions; measure coverage across model outputs; validate explanation consistency,SHAP/LIME Feature Importance Consistency,0.85,Score (0-1),Ensure Feature Importance Consistency Score is >= 0.85,MAPPED
Inference,Explainability,Inaccessible training data,"Training data not available for inspection, limiting explanation quality.",HFT-019,Document and provide access to training data information,"Use Transformers model cards to document training data information (size, source, license, availability). Implement data documentation standards and make summaries available to users within privacy constraints.",GOVERN-1.6,Training data documentation completeness; Accessibility score; License clarity percentage,Audit model card for data documentation; verify summaries are accessible; check license information clarity,Procedural rule - documentation and access control,,,,SKIPPED
Inference,Intellectual property,Confidential data in prompt,Confidential or proprietary information included in model prompts.,HFT-020,Detect and protect confidential data in prompts,"Implement confidentiality scanning in Transformers inference preprocessing. Detect patterns associated with confidential data (API keys, credentials, proprietary patterns). Log and alert on sensitive data detection.",GOVERN-1.1,Confidential data detection rate; Exposure incident count; Alert generation rate,Scan prompts for sensitive patterns; measure detection accuracy; track alert frequency and response,Confidential Data Detection Rate,96,Percentage (%),Ensure Confidential Data Detection Rate is >= 96%,MAPPED
Inference,Intellectual property,IP information in prompt,Copyrighted or IP-protected information included in prompts.,HFT-021,Monitor and control IP material in prompts,Use Transformers with copyright/IP detection layers to identify known protected works in prompts. Implement filtering and logging mechanisms. Document IP handling policies in model cards.,GOVERN-1.1,IP detection rate; Protected content identification accuracy; Filtering effectiveness percentage,Scan for known copyright patterns; measure detection specificity; evaluate filtering success rate,IP Material Detection Rate,94,Percentage (%),Ensure IP Material Detection Rate is >= 94%,MAPPED
Inference,Intellectual property,Copyright infringement,Model generates content similar or identical to copyrighted works.,HFT-022,Detect and prevent copyright-infringing output,Implement output filtering using similarity matching against known copyrighted works. Use Transformers with post-processing pipelines to detect and flag potentially infringing content. Log high-similarity outputs for review.,GOVERN-1.1,Copyright similarity detection rate; Infringing content identification rate; False positive percentage,Compare outputs against copyright database; measure detection accuracy; audit flagged cases for legal review,Copyright Similarity Detection Rate,92,Percentage (%),Ensure Copyright Similarity Detection Rate is >= 92%,MAPPED
Inference,Intellectual property,Revealing confidential information,Model reveals confidential or proprietary information in outputs.,HFT-023,Implement output inspection for confidential content,"Use Transformers with output filtering pipelines to detect confidential patterns (credentials, proprietary keywords) before returning results. Log suspicious outputs for audit. Implement redaction mechanisms.",GOVERN-1.1,Confidential content detection rate; Output redaction coverage; Unauthorized disclosure incidents,Scan outputs for sensitive patterns; measure redaction completeness; track disclosure incident frequency,Confidential Content Detection Rate,97,Percentage (%),Ensure Confidential Content Detection Rate is >= 97%,MAPPED
Inference,Value alignment,Toxic output,"Model produces hateful, abusive, profane, or obscene content.",HFT-024,Detect and filter toxic model outputs,Use Transformers with toxicity detection pipelines (using models like perspective-api integration) to identify harmful outputs before returning to users. Implement content filtering and logging of flagged content.,GOVERN-1.2; MEASURE-2.11,Toxicity detection rate; Content filtering pass rate; Toxic content percentage in outputs,Run toxicity classification on model outputs; measure detection sensitivity; track percentage of flagged harmful content,Toxicity Detection Rate,91,Percentage (%),Ensure Toxicity Detection Rate is >= 91%,MAPPED
Inference,Value alignment,Over- or under-reliance,Users place inappropriate trust (over or under) in model outputs.,HFT-025,Measure and communicate model confidence and limitations,Use Transformers output confidence scores and implement uncertainty quantification. Provide confidence indicators in output metadata. Document model limitations and appropriate use cases in model cards.,GOVERN-1.2; MEASURE-2.2,Confidence calibration score; Prediction uncertainty quantification; User appropriateness metrics,Calculate calibration between confidence scores and accuracy; measure prediction uncertainty consistency; survey users on appropriate reliance,Confidence Calibration Score,0.85,Score (0-1),Ensure Confidence Calibration Score is >= 0.85,MAPPED
Inference,Misuse,Dangerous use,Model used with intent to harm people.,HFT-026,Monitor and restrict dangerous model usage,"Implement usage monitoring on Transformers inference endpoints to detect patterns associated with dangerous activities (violence, hate, illegal activities). Implement access controls and logging. Document prohibited uses in model cards.",GOVERN-1.7,Dangerous usage pattern detection rate; Incident response time; Usage policy violation percentage,Monitor query patterns for harmful intent; measure detection latency; track policy violation incidents,Dangerous Usage Pattern Detection Rate,88,Percentage (%),Ensure Dangerous Usage Pattern Detection Rate is >= 88%,MAPPED
Inference,Misuse,Improper usage,Model used for unintended purposes or outside design scope.,HFT-027,Document intended use and monitor for improper applications,Use Transformers model cards to clearly document intended use cases and explicitly list prohibited uses. Implement usage monitoring to detect out-of-scope applications. Log usage patterns for analysis.,GOVERN-1.7; GOVERN-1.2,Out-of-scope usage detection rate; Intended use documentation clarity; Usage policy adherence percentage,Document intended use clearly; monitor query types against defined scope; calculate out-of-scope query percentage,Procedural rule - documentation and usage monitoring,,,,SKIPPED
