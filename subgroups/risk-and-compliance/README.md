# Security and Compliance Work Group

## Risk and Compliance Subgroup

> [!IMPORTANT]
> The Risk & Compliance (R&C) SubGroup meets, bi-weekly on Tuesdays @10am US ET, 7am US Pacific, 14:00 UTC/GMT using Zoom. Select the "Need an invite" link on our [LF AI & Data calendar entry](https://zoom-lfx.platform.linuxfoundation.org/meeting/92920325389?password=c20c64b0-eec4-4b87-bb45-1b14ca247654)  and join us!
>   - Slack: [#risk-and-compliance-subgroup](https://lfaifoundation.slack.com/archives/C09DTG6A6RE)
>   - Meeting Agendas/Notes: [Google Doc](https://docs.google.com/document/d/1ZwTE084sDxHIk-BfCVSkpofbAz0BuWsWUdYnYeSgl6w/edit?tab=t.0#heading=h.5ac6du8f8k7t)


This repository is used to develop and manage the Risk and Compliance SubGroup's assets. This may include use cases, compliance profiles and other artifacts typically in [NIST OSCAL format](https://pages.nist.gov/OSCAL-Reference/models/), risk taxonomies, and more.

> [!IMPORTANT]
> **Comments invited on the OSCAL Mapping Best Practices white paper**. Please see the [Initiative below](#initiatives)

### Leadership

- R&C Chairs: 

Anca Sailer (IBM)
    - ancas@us.ibm.com
    - LFAI Slack: @Anca Sailer

Deep Patel (Cisco)
    - deepchand@gmail.com
    - LFAI Slack: @Deep Patel

Hubbert Smith (i4ops)
    - hubbert@i4ops.com
    - LFAI Slack: @Hubbert Smith

### Mission statement

 <div style="background-color: #C8F0FF;">
 <p style="margin: 8px;">
  The Risk and Compliance Subgroup of the LF AI Security & Compliance Work Group addresses AI technologies and regulatory compliance in mission-critical environments. Our mission has two objectives: establishing secure AI production governance frameworks and leveraging AI to enhance organizational process governance. We implement compliance-as-code standards, contributing to and utilizing CNCF compliance and policy projects to build modular, interoperable AI compliance solutions. This creates a self-supporting cycle where robust governance ensures secure AI development and deployment, while AI-powered governance systems enhance compliance in regulated environments. Our vision is to establish a comprehensive, community-driven AI compliance approach that empowers organizations to deploy secure, trustworthy, auditable, and regulation-aligned AI systems, fostering innovation and cloud-native AI adoption.</p>
</div>

### How to get involved

#### LFAI Accounts

You will need to assure you have accounts created in both the Linux Foundation (LF) and the LF AI & Data Foundation (LFAI):

Follow the instructions provided in the top-level, work group README here:
- [Creating LF accounts](https://github.com/lfai/security-and-compliance?tab=readme-ov-file#creating-lf-accounts)


#### Meetings and mailing list

R&C subgroup meetings will be held bi-weekly

- 10am US ET, 7am US Pacific, 14:00 UTC/GMT
    - *Series starts on Tuesday, September 2nd*
    - Select the "Need an invite" link on our [LF AI & Data calendar entry](https://zoom-lfx.platform.linuxfoundation.org/meeting/92920325389?password=c20c64b0-eec4-4b87-bb45-1b14ca247654) and join us!

##### Meeting sign-up

The LF AI & Data Foundation allows for self-registration to meetings via the foundation's Zoom.

- Using the LF AI & Data Community Calendar: [https://zoom-lfx.platform.linuxfoundation.org/meetings/lf-ai-foundation](https://zoom-lfx.platform.linuxfoundation.org/meetings/lf-ai-foundation?view=week)

- Find and click on the meeting that interests you, and click "Register" to sign up.

##### Subscribe to the mailing list

- Email: [security-and-compliance-work-group+subscribe@lists.lfaidata.foundation ](mailto:security-and-compliance-work-group+subscribe@lists.lfaidata.foundation )

#### Agendas, Meeting minutes

<div><img src="../../images/logos/google-drive-40x36.png" style="width: 20px; margin-right: 10px;" alt="Google drive logo">
Request access to the project's <span style="color: gray;"><strong>Google drive folder</strong></span> which will be used to hold agendas, meeting notes, presentations, etc.

- [Link to R&C Google doc](https://docs.google.com/document/d/1Y5EBzZPD0PjsCOsVwu4O1SiL0YUySzxwTfJmaVu44BA/edit?tab=t.0)

#### Communication channels

<div><img src="../../images/logos/slack-logo-40x40.png" style="width: 20px; margin-right: 10px;" alt="Slack logo">
Please join the <span style="color: gray;"><strong>LF AI & Data Foundation Slack</strong></span> for informal communication with work group members and other registered users:</p>
</div>

- https://slack.lfaidata.foundation/

then join the R&C subproject channel:

- [#risk-and-compliance-subgroup](https://lfaifoundation.slack.com/archives/C09DTG6A6RE)

---

### Initiatives

1. [Best Practices and Benchmarks for AI](./Initiative-BestPracticesBenchmarksForAI.md)
2. [OSCAL Mapping Best Practices](https://docs.google.com/document/d/1OInb3KA000ELjgjk1uPjaVl5ONaYl4u1/edit?usp=sharing&ouid=108830014708799752840&rtpof=true&sd=true). An [issue](https://github.com/lfai/security-and-compliance/issues/31) has been created to provide comments on the white paper.

---

## Code of Conduct

The subgroup adheres to the LF AI & Data's Code of Conduct (CoC) as published here:

- https://github.com/lfai/foundation/blob/main/codeofconduct.md
